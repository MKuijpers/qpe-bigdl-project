{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dir = os.scandir('data/')\n",
    "experiments = list(filter(lambda x: x.name.endswith(\".pickle\"), dir))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for experiment in experiments:\n",
    "    dffile = open(experiment.path, 'rb')      \n",
    "    read_df = pickle.load(dffile)\n",
    "    read_df = read_df[['max_epochs', 'executor_memory', 'executor_cores', 'model', 'accuracy', 'time']]\n",
    "    df = pd.concat([df, read_df])\n",
    "\n",
    "\n",
    "acc_df = pd.DataFrame({'y': df[\"accuracy\"],\n",
    "                       'epochs': df[\"max_epochs\"],\n",
    "                       'memory': df[\"executor_memory\"],\n",
    "                       'cores': df[\"executor_cores\"],\n",
    "                       'model': df[\"model\"]})\n",
    "\n",
    "time_df = pd.DataFrame({'y': df[\"time\"],\n",
    "                        'epochs': df[\"max_epochs\"],\n",
    "                        'memory': df[\"executor_memory\"],\n",
    "                        'cores': df[\"executor_cores\"],\n",
    "                        'model': df[\"model\"]})\n",
    "\n",
    "print(f\"Imported {len(experiments)} experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x_and_y(data_df):\n",
    "    output_column = \"epochs\"\n",
    "    data_X = data_df[[x for x in data_df.columns if x != output_column]]\n",
    "    data_y = data_df[[output_column]]\n",
    "    data_y = data_y.to_numpy().flatten()\n",
    "    return data_X, data_y\n",
    "\n",
    "def numerize_model_names(df_data):\n",
    "    numerized = df_data.copy()\n",
    "    numerized['model'] = numerized['model'].apply(lambda x: -1 if x == \"bi-rnn\" else 1)\n",
    "    return numerized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn import over_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, linear_model, svm, metrics, tree\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_df_numerized_models = numerize_model_names(acc_df)\n",
    "time_df_numerized_models = numerize_model_names(time_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def model_testing(input_df, learning_models, x_axis, plot_name_prefix, x_label):\n",
    "    \n",
    "    error_df = pd.DataFrame({\"model\": [], \"err\": [], \"baseline_err\": [], \"err^2\": []})\n",
    "    \n",
    "    for model in learning_models:\n",
    "        print(f\"=========   {plot_name_prefix}: {model}   ==========\")\n",
    "        absolute_errors = []\n",
    "        absolute_errors_baseline = []\n",
    "        squared_errors = []\n",
    "\n",
    "        feature_vectors, labels = df_to_x_and_y(input_df)\n",
    "\n",
    "        for i in range(0, 10):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(feature_vectors,\n",
    "                                                                labels,\n",
    "                                                                train_size=int(.80 * len(input_df)),\n",
    "                                                                test_size=int(.20 * len(input_df)))\n",
    "\n",
    "            trained_model = model.fit(x_train, y_train)\n",
    "            predictions = trained_model.predict(x_test)\n",
    "            absolute_errors.append(mean_absolute_error(y_test, predictions))\n",
    "            squared_errors.append(mean_squared_error(y_test, predictions))\n",
    "            baseline_predictions = [40 for _ in range(len(predictions))]\n",
    "            absolute_errors_baseline.append(mean_absolute_error(y_test, baseline_predictions))\n",
    "        \n",
    "        mean_abs_err = np.mean(np.array(absolute_errors))\n",
    "        mean_abs_baseline_error = np.mean(np.array(absolute_errors_baseline))\n",
    "        mean_sqrd_err = np.mean(np.array(squared_errors))\n",
    "        print(f'Mean absolute error: {mean_abs_err}')\n",
    "        print(f'Mean absolute error baseline: {mean_abs_baseline_error}')\n",
    "        print(f'Mean squared error: {mean_sqrd_err}')\n",
    "        \n",
    "        error_df = error_df.append({\"model\": model, \"err\": mean_abs_err, \"baseline_err\": mean_abs_baseline_error, \"err^2\": mean_sqrd_err}, ignore_index=True)\n",
    "        error_df[\"% improv\"] = (error_df[\"baseline_err\"] - error_df[\"err\"]) / error_df[\"baseline_err\"] * 100\n",
    "        error_df[[\"err\", \"baseline_err\", \"err^2\", \"% improv\"]] = error_df[[\"err\", \"baseline_err\", \"err^2\", \"% improv\"]].apply(lambda x: round(x, 2))\n",
    "        \n",
    "\n",
    "        for learning_model in [-1, 1]:\n",
    "            for cores in [8, 16]:\n",
    "                for memory in [4, 32]:\n",
    "                    input_data = [[i, memory, cores, learning_model] for i in x_axis]\n",
    "                    predictions = trained_model.predict(input_data)\n",
    "                    learning_model_name = \"le\" if learning_model == 1 else \"br\"\n",
    "                    plt.plot(x_axis, predictions, label=f\"{learning_model_name} C:{cores} M:{memory}\")\n",
    "\n",
    "        plt.scatter(input_df[\"y\"], input_df[\"epochs\"])\n",
    "        plt.legend()\n",
    "        plt.plot(x_axis, predictions)\n",
    "        plt.title(model)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.ylabel(\"Epochs\")\n",
    "        plt.xlabel(x_label)\n",
    "        plt.show()\n",
    "    \n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "time_learning_models = [\n",
    "                        SVR(),\n",
    "                        tree.DecisionTreeRegressor(),\n",
    "                        MLPRegressor(),\n",
    "                        linear_model.BayesianRidge(),\n",
    "                        linear_model.ARDRegression(),\n",
    "                       ]\n",
    "\n",
    "error_df = model_testing(time_df_numerized_models, time_learning_models, [i * 10 for i in range(100)], \"Time\", \"Time (s)\")\n",
    "\n",
    "error_df = error_df.sort_values(by=['err'])\n",
    "\n",
    "print(error_df.to_latex(index=False, caption='Black Box model errors for predicting epochs based on time', label='black-box-time-model-errors'))\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "acc_learning_models = [\n",
    "                        SVR(),\n",
    "                        tree.DecisionTreeRegressor(),\n",
    "                        MLPRegressor(),\n",
    "                        linear_model.BayesianRidge(),\n",
    "                        linear_model.ARDRegression(),\n",
    "                       ]\n",
    "\n",
    "error_df = model_testing(acc_df_numerized_models, acc_learning_models, [i / 100 for i in range(100)], \"Accuracy\", \"Accuracy\")\n",
    "error_df = error_df.sort_values(by=['err'])\n",
    "print(error_df.to_latex(index=False, caption='Black Box model errors for predicting epochs based on accuracy', label='black-box-accuracy-model-errors'))\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Cores comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_cpu_graph(input_df, model, target, plot_title):\n",
    "    print(f\"=========   Varying cores using {model}   ==========\")\n",
    "    \n",
    "    feature_vectors, labels = df_to_x_and_y(input_df)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature_vectors,\n",
    "                                                        labels,\n",
    "                                                        train_size=int(.80 * len(input_df)),\n",
    "                                                        test_size=int(.20 * len(input_df)))\n",
    "\n",
    "    trained_model = model.fit(x_train, y_train)\n",
    "    \n",
    "    x_axis = list(range(1,64+1))\n",
    "    learning_model = 1\n",
    "    input_data = [[target, 32, i, learning_model] for i in x_axis]\n",
    "    predictions = trained_model.predict(input_data)\n",
    "    plt.plot(x_axis, predictions)\n",
    "    \n",
    "    plt.plot(x_axis, predictions)\n",
    "    plt.title(f\"{model}: {plot_title}\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.ylabel(\"Epochs\")\n",
    "    plt.xlabel(\"Cores\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0.9\n",
    "plot_cpu_graph(acc_df_numerized_models, linear_model.ARDRegression(), target, f\"Epochs for {target * 100}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 300\n",
    "plot_cpu_graph(time_df_numerized_models, linear_model.ARDRegression(), target, f\"Epochs for {target} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
