{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dataset_pickle = 'data/dataset.pickle'\n",
    "\n",
    "with open(dataset_pickle, 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "\n",
    "assert df is not None, f'The dataset pickle file {dataset_pickle} is not found'\n",
    "\n",
    "        \n",
    "acc_df = pd.DataFrame({'y': df[\"accuracy\"],\n",
    "                       'epochs': df[\"max_epochs\"],\n",
    "                       'memory': df[\"executor_memory\"],\n",
    "                       'cores': df[\"executor_cores\"],\n",
    "                       'model': df[\"model\"]})\n",
    "\n",
    "time_df = pd.DataFrame({'y': df[\"time\"],\n",
    "                        'epochs': df[\"max_epochs\"],\n",
    "                        'memory': df[\"executor_memory\"],\n",
    "                        'cores': df[\"executor_cores\"],\n",
    "                        'model': df[\"model\"]})\n",
    "\n",
    "print(f\"Imported {len(dataset_pickle)} experiments!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_acc_df = rp.summary_cont(acc_df.groupby(['model', 'epochs', 'cores', 'memory']))['y']\n",
    "summary_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_time_df = rp.summary_cont(time_df.groupby(['model', 'epochs', 'cores', 'memory']))['y']\n",
    "summary_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_analysis(input_df):\n",
    "    model = ols('y ~ C(model)*epochs*cores*memory', input_df).fit()\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    res['PR(>F) < 0.05'] = res['PR(>F)'] < 0.05\n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res, acc_model = anova_analysis(acc_df)\n",
    "print(\"Accuracy ANOVA Analysis\")\n",
    "acc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_res, time_model = anova_analysis(time_df)\n",
    "print(\"Time ANOVA Analysis\")\n",
    "time_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_model_acc = ols('epochs ~ C(model)*cores*memory*y', acc_df).fit()\n",
    "epoch_model_time = ols('epochs ~ C(model)*cores*memory*y', time_df).fit()\n",
    "\n",
    "def epoch_model_predict(trained_model, model, cores, memory, y):\n",
    "    assert model.lower() in ['bi-rnn', 'lenet5'], 'unsupported model (supported: bi-rnn or lenet5)'\n",
    "    assert cores > 0, 'impossible to run on 0 cores'\n",
    "    assert memory > 0, 'impossible to run without memory'\n",
    "    assert y > 0, 'either time or accuracy should be >0 (time or accuracy depends on the trained model)'\n",
    "    return trained_model.predict(exog={'model': model.lower(), 'cores': cores, 'memory': memory, 'y': y})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_acc = epoch_model_predict(epoch_model_acc, model='Bi-rnn', cores=10, memory=64, y=0.6)\n",
    "prediction_with_time = epoch_model_predict(epoch_model_time, model='Bi-rnn', cores=10, memory=64, y=300)\n",
    "\n",
    "print(f'Predicted epochs with accuracy: {prediction_with_acc}')\n",
    "print(f'Predicted epochs with time: {prediction_with_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentages_variation_explained(acc_model, time_model):\n",
    "    df_time_test = sm.stats.anova_lm(time_model, typ=1)[['sum_sq']]\n",
    "    df_acc_test = sm.stats.anova_lm(acc_model, typ=1)[['sum_sq']]\n",
    "\n",
    "    df_acc_test['Percentage of variation explained (accuracy)'] = df_acc_test['sum_sq']/df_acc_test['sum_sq'].sum() * 100\n",
    "    df_time_test['Percentage of variation explained (time)'] = df_time_test['sum_sq']/df_time_test['sum_sq'].sum() * 100\n",
    "\n",
    "    df_acc_test = df_acc_test.drop('sum_sq', axis=1)\n",
    "    df_acc_test['Percentage of variation explained (time)'] = df_time_test['Percentage of variation explained (time)']\n",
    "    df_acc_test['Percentage of variation explained (accuracy)'] = df_acc_test['Percentage of variation explained (accuracy)'].apply(lambda x: f'{x:.2f}%')\n",
    "    df_acc_test['Percentage of variation explained (time)'] = df_acc_test['Percentage of variation explained (time)'].apply(lambda x: f'{x:.2f}%')\n",
    "    return df_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *PrePoch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Weights\n",
    "w1 = 0.1\n",
    "w2 = 0.9\n",
    "\n",
    "# System-Parameters\n",
    "model = 'lenet5'\n",
    "cores = 10\n",
    "memory = 64\n",
    "\n",
    "# Target Parameters\n",
    "target_accuracy = 0.1\n",
    "target_time = 300\n",
    "\n",
    "# Predictions\n",
    "prediction_with_acc = epoch_model_predict(epoch_model_acc, model=model, cores=cores, memory=memory, y=target_accuracy)\n",
    "prediction_with_time = epoch_model_predict(epoch_model_time, model=model, cores=cores, memory=memory, y=target_time)\n",
    "\n",
    "# Prepoch results\n",
    "prepoch = w1 * prediction_with_acc + w2 * prediction_with_time\n",
    "\n",
    "print(prepoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check normality of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "for name, df in acc_df.groupby(['model', 'epochs', 'cores', 'memory']):\n",
    "    counter = counter + 1\n",
    "    df = df.reset_index()\n",
    "    for i, row in df.iterrows():\n",
    "        y_pred = acc_model.predict(exog={\n",
    "            'epochs': row['epochs'] ,\n",
    "            'model': row['model'], \n",
    "            'cores': row['cores'], \n",
    "            'memory': row['memory']\n",
    "        })[0]\n",
    "\n",
    "        error = y_pred - row['y'] \n",
    "        \n",
    "        df.at[i,'y_pred'] = y_pred\n",
    "        df.at[i,'error'] = error\n",
    "        \n",
    "    data = df['error']\n",
    "    stat, p = shapiro(data)\n",
    "    \n",
    "    # manual inspection\n",
    "    if counter is 4:\n",
    "        qqplot(data, line='s')\n",
    "        pyplot.show()\n",
    "    \n",
    "    result_df = result_df.append({'experiment': name, 'p-value (Shapiro-Wilk)': p}, ignore_index=True)\n",
    "\n",
    "result_df['Reject Null Hypothesis'] = result_df['p-value (Shapiro-Wilk)'] < 0.05\n",
    "print(result_df.to_latex(index=False, caption='', label=''))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
