{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dataset_pickle = 'data/dataset.pickle'\n",
    "\n",
    "with open(dataset_pickle, 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "\n",
    "assert df is not None, f'The dataset pickle file {dataset_pickle} is not found'\n",
    "\n",
    "        \n",
    "acc_df = pd.DataFrame({'y': df[\"accuracy\"],\n",
    "                       'epochs': df[\"max_epochs\"],\n",
    "                       'memory': df[\"executor_memory\"],\n",
    "                       'cores': df[\"executor_cores\"],\n",
    "                       'model': df[\"model\"]})\n",
    "\n",
    "time_df = pd.DataFrame({'y': df[\"time\"],\n",
    "                        'epochs': df[\"max_epochs\"],\n",
    "                        'memory': df[\"executor_memory\"],\n",
    "                        'cores': df[\"executor_cores\"],\n",
    "                        'model': df[\"model\"]})\n",
    "\n",
    "print(f\"Imported {len(dataset_pickle)} experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_acc_df = rp.summary_cont(acc_df.groupby(['model', 'epochs', 'cores', 'memory']))['y']\n",
    "summary_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_time_df = rp.summary_cont(time_df.groupby(['model', 'epochs', 'cores', 'memory']))['y']\n",
    "summary_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_analysis(input_df):\n",
    "    model = ols('y ~ C(model)*epochs*cores*memory', input_df).fit()\n",
    "    \n",
    "    res = sm.stats.anova_lm(model, typ=2)\n",
    "    res['PR(>F) < 0.05'] = res['PR(>F)'] < 0.05\n",
    "    return res, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res, acc_model = anova_analysis(acc_df)\n",
    "print(\"Accuracy ANOVA Analysis\")\n",
    "acc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_res, time_model = anova_analysis(time_df)\n",
    "print(\"Time ANOVA Analysis\")\n",
    "time_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_model_acc = ols('epochs ~ C(model)*cores*memory*y', acc_df).fit()\n",
    "epoch_model_time = ols('epochs ~ C(model)*cores*memory*y', time_df).fit()\n",
    "\n",
    "def epoch_model_predict(trained_model, model, cores, memory, y):\n",
    "    assert model.lower() in ['bi-rnn', 'lenet5'], 'unsupported model (supported: bi-rnn or lenet5)'\n",
    "    assert cores > 0, 'impossible to run on 0 cores'\n",
    "    assert memory > 0, 'impossible to run without memory'\n",
    "    assert y > 0, 'either time or accuracy should be >0 (time or accuracy depends on the trained model)'\n",
    "    return trained_model.predict(exog={'model': model.lower(), 'cores': cores, 'memory': memory, 'y': y})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_acc = epoch_model_predict(epoch_model_acc, model='Bi-rnn', cores=10, memory=64, y=0.6)\n",
    "prediction_with_time = epoch_model_predict(epoch_model_time, model='Bi-rnn', cores=10, memory=64, y=300)\n",
    "\n",
    "print(f'Predicted epochs with accuracy: {prediction_with_acc}')\n",
    "print(f'Predicted epochs with time: {prediction_with_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentages_variation_explained(acc_model, time_model):\n",
    "    df_time_test = sm.stats.anova_lm(time_model, typ=1)[['sum_sq']]\n",
    "    df_acc_test = sm.stats.anova_lm(acc_model, typ=1)[['sum_sq']]\n",
    "\n",
    "    df_acc_test['Percentage of variation explained (accuracy)'] = df_acc_test['sum_sq']/df_acc_test['sum_sq'].sum() * 100\n",
    "    df_time_test['Percentage of variation explained (time)'] = df_time_test['sum_sq']/df_time_test['sum_sq'].sum() * 100\n",
    "\n",
    "    df_acc_test = df_acc_test.drop('sum_sq', axis=1)\n",
    "    df_acc_test['Percentage of variation explained (time)'] = df_time_test['Percentage of variation explained (time)']\n",
    "    df_acc_test['Percentage of variation explained (accuracy)'] = df_acc_test['Percentage of variation explained (accuracy)'].apply(lambda x: f'{x:.2f}%')\n",
    "    df_acc_test['Percentage of variation explained (time)'] = df_acc_test['Percentage of variation explained (time)'].apply(lambda x: f'{x:.2f}%')\n",
    "    return df_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check normality of errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
