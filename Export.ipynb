{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 'circymxx' # Enter the ID of the experiment (name of the folder) to export\n",
    "interval = 60 # in seconds for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_to_csv(path, experiment):\n",
    "    jobs = pd.read_csv(f'{experiment.path}/design.csv', sep='\\t')\n",
    "    jobs.columns.values[0] = 'Index'\n",
    "    jobs = jobs[jobs.Index >= 0]\n",
    "    \n",
    "    jobs['accuracy'] = 0.0\n",
    "    jobs['epochs'] = 0\n",
    "    pat = re.compile(\"accuracy: (\\d+\\.\\d+)\")\n",
    "    pat_clock = re.compile(\"Wall clock time is (\\d+\\.\\d+) ms\")\n",
    "    found, not_existing = 0, 0\n",
    "    for idx, row in jobs.iterrows():\n",
    "        filename = f\"{int(row.Index)}-model{row.model}-epochs{row.max_epochs}-executor_memory{row.executor_memory}-executor_cores{row.executor_cores}.log\"\n",
    "        \n",
    "        try:\n",
    "            with open(f'{experiment.path}/{filename}', 'r') as file:\n",
    "                content = file.read()\n",
    "                result = pat.findall(content)\n",
    "                result_wallclock = float(pat_clock.findall(content)[-1])/1000\n",
    "                jobs.at[idx, 'time'] = result_wallclock\n",
    "                jobs.at[idx, 'accuracy'] = result[-1] if len(result) > 0 else 0\n",
    "                jobs.loc[idx, 'epochs'] = len(result)\n",
    "                found += 1\n",
    "        except FileNotFoundError as e:\n",
    "            jobs.at[idx, 'time'] = -1\n",
    "            jobs.at[idx, 'accuracy'] = -1\n",
    "            jobs.loc[idx, 'epochs'] = -1\n",
    "            not_existing += 1\n",
    "    \n",
    "    time = os.stat(f'{experiment.path}/design.csv').st_mtime\n",
    "    dt = datetime.fromtimestamp(time)\n",
    "    jobs.to_csv(f'ex-{dt.strftime(\"%Y-%m-%d_%H:%M\")}.csv')\n",
    "    return (jobs, f'ex-{dt.strftime(\"%Y-%m-%d_%H:%M\")}.csv', found, not_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_results():\n",
    "    dir = os.scandir('raw/')\n",
    "    experiments = list(filter(lambda x: x.is_dir() and x.name[0] != '.' and x.name == EXPERIMENT_ID, dir))\n",
    "    assert len(experiments) > 0, f'The folder {EXPERIMENT_ID} does not exist!'\n",
    "\n",
    "    for experiment in experiments:\n",
    "        if os.path.exists(f'{experiment.path}/design.csv'):\n",
    "            jobs, path, found, not_existing = experiment_to_csv(experiment.path, experiment)\n",
    "            print(f'Results of {experiment} stored in {path}')\n",
    "            print(f'{found} of the {found + not_existing} expected log files are present. The other experiments are probably missing.\\n')\n",
    "            df = pd.read_csv(path)\n",
    "            df = df[['max_epochs', 'executor_memory', 'executor_cores', 'model', 'accuracy', 'time']]\n",
    "        else:\n",
    "            raise Exception(f'{experiment.path}/design.csv not found!')\n",
    "    done = not_existing == 0\n",
    "    return df, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = fetch_results()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while done:\n",
    "    df, done = fetch_results()\n",
    "    clear_output(wait=True)\n",
    "    dt = datetime.fromtimestamp(time.time())\n",
    "    print(f'Last update: {dt.strftime(\"%H:%M:%S\")}')\n",
    "    display(df)\n",
    "    time.sleep(interval)\n",
    "    \n",
    "with open(f'{EXPERIMENT_ID}.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
